{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ebd943d",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "# ðŸŽ¥ GerÃ§ek ZamanlÄ± Webcam Inference\n",
    "---\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ed8bd9d",
   "metadata": {},
   "source": [
    "# Ã–nce python modelini aÅŸaÄŸÄ±ya bÄ±rakÄ±yorum.Bundan Ã¶nceki projede kullanÄ±lan aynÄ± kodlar kullanÄ±lÄ±caktÄ±r.Ã–nce .pth ve .pt dosyalarÄ±nÄ± oluÅŸturalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e95870bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [02:33<00:00, 1.11MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset hazÄ±r, model oluÅŸturuluyor...\n",
      "Kullanilan cihaz: cpu\n",
      "ImprovedCNN(\n",
      "  (features): Sequential(\n",
      "    (0): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (1): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (3): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (4): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (6): ConvBlock(\n",
      "      (block): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (2): ReLU(inplace=True)\n",
      "      )\n",
      "    )\n",
      "    (7): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (8): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=256, out_features=128, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=128, out_features=10, bias=True)\n",
      "  )\n",
      ")\n",
      "Epoch [1/1] | Train Loss: 1.5635 | Train Acc: 41.40% | Test Acc: 51.17%\n",
      "  -> Yeni en iyi model kaydedildi! (best_model.pth, acc=51.17%)\n",
      "Egitim tamamlandi. En iyi test accuracy: 51.17\n",
      "TorchScript modeli kaydedildi: model_ts.pt\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# --------------------------\n",
    "# GeliÅŸtirilmiÅŸ CNN Mimarisi\n",
    "# --------------------------\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, padding=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=kernel_size, padding=padding),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "\n",
    "class ImprovedCNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ImprovedCNN, self).__init__()\n",
    "\n",
    "        self.features = nn.Sequential(\n",
    "            # GiriÅŸ: [B, 3, 64, 64]\n",
    "            ConvBlock(3, 32),              # [B, 32, 64, 64]\n",
    "            ConvBlock(32, 64),             # [B, 64, 64, 64]\n",
    "            nn.MaxPool2d(2, 2),            # [B, 64, 32, 32]\n",
    "\n",
    "            ConvBlock(64, 128),            # [B, 128, 32, 32]\n",
    "            ConvBlock(128, 128),           # [B, 128, 32, 32]\n",
    "            nn.MaxPool2d(2, 2),            # [B, 128, 16, 16]\n",
    "\n",
    "            ConvBlock(128, 256),           # [B, 256, 16, 16]\n",
    "            nn.MaxPool2d(2, 2),            # [B, 256, 8, 8]\n",
    "\n",
    "            # Global Average Pooling: [B, 256, 1, 1]\n",
    "            nn.AdaptiveAvgPool2d((1, 1))\n",
    "        )\n",
    "\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),                  # [B, 256]\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.Linear(128, num_classes)    # [B, num_classes]\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.classifier(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# Veri hazÄ±rlÄ±ÄŸÄ±\n",
    "# --------------------------\n",
    "\n",
    "# CIFAR-10 iÃ§in tipik normalize deÄŸerleri (RGB)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((64, 64)),\n",
    "    transforms.ToTensor(),  # 0-1\n",
    "    transforms.Normalize(\n",
    "        mean=[0.4914, 0.4822, 0.4465],\n",
    "        std=[0.2470, 0.2435, 0.2616]\n",
    "    ),\n",
    "])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root=\"./data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True, num_workers=2)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=False, num_workers=2)\n",
    "\n",
    "print(\"Dataset hazÄ±r, model oluÅŸturuluyor...\")\n",
    "\n",
    "# --------------------------\n",
    "# Model, cihaz, loss, optimizer\n",
    "# --------------------------\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Kullanilan cihaz:\", device)\n",
    "\n",
    "model = ImprovedCNN(num_classes=10).to(device)\n",
    "print(model)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "# Ä°stersen scheduler da ekleyebilirsin:\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "\n",
    "EPOCHS = 1  # Ä°stersen artÄ±r (10-20 arasÄ± daha makul)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# EÄŸitim + basit eval dÃ¶ngÃ¼sÃ¼\n",
    "# --------------------------\n",
    "\n",
    "best_acc = 0.0\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    # ---- Train ----\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        _, preds = outputs.max(1)\n",
    "        correct += preds.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_acc = 100.0 * correct / total\n",
    "\n",
    "    # ---- Eval (test) ----\n",
    "    model.eval()\n",
    "    correct_test = 0\n",
    "    total_test = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(images)\n",
    "            _, preds = outputs.max(1)\n",
    "            correct_test += preds.eq(labels).sum().item()\n",
    "            total_test += labels.size(0)\n",
    "\n",
    "    test_acc = 100.0 * correct_test / total_test\n",
    "\n",
    "    # scheduler kullanÄ±yorsan burada step:\n",
    "    # scheduler.step()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | \"\n",
    "          f\"Train Loss: {train_loss:.4f} | \"\n",
    "          f\"Train Acc: {train_acc:.2f}% | \"\n",
    "          f\"Test Acc: {test_acc:.2f}%\")\n",
    "\n",
    "    # En iyi modeli kaydet\n",
    "    if test_acc > best_acc:\n",
    "        best_acc = test_acc\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        print(f\"  -> Yeni en iyi model kaydedildi! (best_model.pth, acc={best_acc:.2f}%)\")\n",
    "\n",
    "print(\"Egitim tamamlandi. En iyi test accuracy:\", best_acc)\n",
    "\n",
    "\n",
    "# --------------------------\n",
    "# TorchScript export (LibTorch iÃ§in)\n",
    "# --------------------------\n",
    "\n",
    "# AynÄ± mimariyi yeniden kur\n",
    "export_model = ImprovedCNN(num_classes=10)\n",
    "export_model.load_state_dict(torch.load(\"best_model.pth\", map_location=\"cpu\"))\n",
    "export_model.eval()\n",
    "\n",
    "# Ã–rnek giriÅŸ (dummy input)\n",
    "example_input = torch.randn(1, 3, 64, 64)\n",
    "\n",
    "# TorchScript trace\n",
    "traced_script_module = torch.jit.trace(export_model, example_input)\n",
    "\n",
    "# Kaydet\n",
    "traced_script_module.save(\"model_ts.pt\")\n",
    "\n",
    "print(\"TorchScript modeli kaydedildi: model_ts.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a4275c7",
   "metadata": {},
   "source": [
    "-----\n",
    "\n",
    "# C++ Kodunu yine aÅŸaÄŸÄ±ya bÄ±rakÄ±yorum:\n",
    "\n",
    "```cpp\n",
    "// ---------------------------------------------------------\n",
    "// LibTorch + OpenCV ile GerÃ§ek ZamanlÄ± Webcam Inference\n",
    "// (ImprovedCNN + CIFAR10 Normalize)\n",
    "// ---------------------------------------------------------\n",
    "\n",
    "#include <iostream>\n",
    "#include <fstream>\n",
    "#include <string>\n",
    "#include <vector>\n",
    "\n",
    "#include <torch/script.h>\n",
    "#include <opencv2/opencv.hpp>\n",
    "\n",
    "// CIFAR-10 sÄ±nÄ±f isimleri\n",
    "const std::vector<std::string> CIFAR10_CLASSES = {\n",
    "    \"airplane\",   // 0\n",
    "    \"automobile\", // 1\n",
    "    \"bird\",       // 2\n",
    "    \"cat\",        // 3\n",
    "    \"deer\",       // 4\n",
    "    \"dog\",        // 5\n",
    "    \"frog\",       // 6\n",
    "    \"horse\",      // 7\n",
    "    \"ship\",       // 8\n",
    "    \"truck\"       // 9\n",
    "};\n",
    "\n",
    "// CIFAR-10 Normalize deÄŸerleri (PyTorch ile aynÄ±)\n",
    "const float CIFAR10_MEAN[3] = {0.4914f, 0.4822f, 0.4465f}; // R, G, B\n",
    "const float CIFAR10_STD[3] = {0.2470f, 0.2435f, 0.2616f};\n",
    "\n",
    "torch::Tensor preprocess_image(const cv::Mat &img_bgr, int target_size)\n",
    "{\n",
    "    cv::Mat img;\n",
    "    img_bgr.copyTo(img);\n",
    "\n",
    "    // Resize\n",
    "    cv::resize(img, img, cv::Size(target_size, target_size));\n",
    "\n",
    "    // BGR -> RGB\n",
    "    cv::cvtColor(img, img, cv::COLOR_BGR2RGB);\n",
    "\n",
    "    // uint8 -> float32 [0,1]\n",
    "    cv::Mat img_float;\n",
    "    img.convertTo(img_float, CV_32F, 1.0f / 255.0f);\n",
    "\n",
    "    // Kanal bazlÄ± normalize\n",
    "    {\n",
    "        std::vector<cv::Mat> channels(3);\n",
    "        cv::split(img_float, channels); // R,G,B\n",
    "\n",
    "        for (int c = 0; c < 3; ++c)\n",
    "        {\n",
    "            channels[c] = (channels[c] - CIFAR10_MEAN[c]) / CIFAR10_STD[c];\n",
    "        }\n",
    "\n",
    "        cv::merge(channels, img_float);\n",
    "    }\n",
    "\n",
    "    // HWC -> NHWC tensor\n",
    "    auto tensor_image = torch::from_blob(\n",
    "        img_float.data,\n",
    "        {1, img_float.rows, img_float.cols, 3}, // [N,H,W,C]\n",
    "        torch::TensorOptions().dtype(torch::kFloat32));\n",
    "\n",
    "    // NHWC -> NCHW\n",
    "    tensor_image = tensor_image.permute({0, 3, 1, 2}); // [N,C,H,W]\n",
    "\n",
    "    // BelleÄŸi sabitle\n",
    "    tensor_image = tensor_image.contiguous().clone();\n",
    "\n",
    "    return tensor_image;\n",
    "}\n",
    "\n",
    "torch::Tensor run_inference(torch::jit::script::Module &module,\n",
    "                            const torch::Tensor &input)\n",
    "{\n",
    "    std::vector<torch::jit::IValue> inputs;\n",
    "    inputs.push_back(input);\n",
    "    torch::Tensor output = module.forward(inputs).toTensor();\n",
    "    return output;\n",
    "}\n",
    "\n",
    "int main()\n",
    "{\n",
    "    try\n",
    "    {\n",
    "        std::cout << \"[INFO] Program basladi.\\n\";\n",
    "\n",
    "        // ------------------------------\n",
    "        // 1) Modeli yÃ¼kle\n",
    "        // ------------------------------\n",
    "        const std::string model_path = \"model_ts.pt\";\n",
    "\n",
    "        {\n",
    "            std::ifstream f(model_path);\n",
    "            if (!f.good())\n",
    "            {\n",
    "                std::cerr << \"[HATA] model_ts.pt bulunamadi! Beklenen yer: \"\n",
    "                          << model_path << \"\\n\";\n",
    "                std::cout << \"Enter'a basip cikabilirsin...\\n\";\n",
    "                std::cin.get();\n",
    "                return -1;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        std::cout << \"[INFO] Model yukleniyor...\\n\";\n",
    "        torch::jit::script::Module module = torch::jit::load(model_path);\n",
    "        module.to(torch::kCPU);\n",
    "        module.eval();\n",
    "        std::cout << \"[OK] Model yÃ¼klendi, CPU'da ve eval modunda.\\n\";\n",
    "\n",
    "        // ------------------------------\n",
    "        // 2) Webcam aÃ§\n",
    "        // ------------------------------\n",
    "        cv::VideoCapture cap(0); // 0 = varsayilan kamera\n",
    "\n",
    "        if (!cap.isOpened())\n",
    "        {\n",
    "            std::cerr << \"[HATA] Kamera acilamadi!\\n\";\n",
    "            std::cout << \"Enter'a basip cikabilirsin...\\n\";\n",
    "            std::cin.get();\n",
    "            return -1;\n",
    "        }\n",
    "\n",
    "        std::cout << \"[INFO] Webcam acildi. 'q' tusuna basarak cikabilirsin.\\n\";\n",
    "\n",
    "        const int target_size = 64;\n",
    "\n",
    "        while (true)\n",
    "        {\n",
    "            cv::Mat frame;\n",
    "            cap >> frame; // kameradan bir frame oku\n",
    "\n",
    "            if (frame.empty())\n",
    "            {\n",
    "                std::cerr << \"[WARN] Bos frame geldi, devam ediyorum...\\n\";\n",
    "                continue;\n",
    "            }\n",
    "\n",
    "            // ------------------------------\n",
    "            // 3) Preprocess -> Tensor\n",
    "            // ------------------------------\n",
    "            torch::Tensor input_tensor = preprocess_image(frame, target_size);\n",
    "\n",
    "            // ------------------------------\n",
    "            // 4) Inference\n",
    "            // ------------------------------\n",
    "            torch::Tensor output = run_inference(module, input_tensor);\n",
    "\n",
    "            // ------------------------------\n",
    "            // 5) Postprocess: softmax + argmax\n",
    "            // ------------------------------\n",
    "            torch::Tensor probs = torch::softmax(output, 1);\n",
    "            torch::Tensor pred_class = probs.argmax(1);\n",
    "\n",
    "            int pred_idx = pred_class.item<int>();\n",
    "            std::string pred_name = \"unknown\";\n",
    "\n",
    "            if (pred_idx >= 0 && pred_idx < static_cast<int>(CIFAR10_CLASSES.size()))\n",
    "            {\n",
    "                pred_name = CIFAR10_CLASSES[pred_idx];\n",
    "            }\n",
    "\n",
    "            // ------------------------------\n",
    "            // 6) Sonucu frame Ã¼zerine yaz\n",
    "            // ------------------------------\n",
    "            std::string text = \"Pred: \" + pred_name + \" (idx=\" + std::to_string(pred_idx) + \")\";\n",
    "            cv::putText(frame, text,\n",
    "                        cv::Point(10, 30),\n",
    "                        cv::FONT_HERSHEY_SIMPLEX,\n",
    "                        0.8,\n",
    "                        cv::Scalar(0, 255, 0),\n",
    "                        2);\n",
    "\n",
    "            // FPS vs. istersek buraya ekleyebiliriz.\n",
    "\n",
    "            // Frame'i gÃ¶ster\n",
    "            cv::imshow(\"Real-time CIFAR10 Inference\", frame);\n",
    "\n",
    "            // 'q' veya ESC ile cik\n",
    "            char key = static_cast<char>(cv::waitKey(1));\n",
    "            if (key == 'q' || key == 27)\n",
    "            {\n",
    "                std::cout << \"[INFO] Kullanici cikis istegi verdi.\\n\";\n",
    "                break;\n",
    "            }\n",
    "        }\n",
    "\n",
    "        cap.release();\n",
    "        cv::destroyAllWindows();\n",
    "\n",
    "        std::cout << \"[INFO] Program sonlandi. Enter'a basip cikabilirsin...\\n\";\n",
    "        std::cin.get();\n",
    "    }\n",
    "    catch (const c10::Error &e)\n",
    "    {\n",
    "        std::cerr << \"[EXCEPTION - c10] \" << e.what() << \"\\n\";\n",
    "        std::cout << \"Enter'a basip cikabilirsin...\\n\";\n",
    "        std::cin.get();\n",
    "        return -1;\n",
    "    }\n",
    "    catch (const std::exception &e)\n",
    "    {\n",
    "        std::cerr << \"[EXCEPTION - std] \" << e.what() << \"\\n\";\n",
    "        std::cout << \"Enter'a basip cikabilirsin...\\n\";\n",
    "        std::cin.get();\n",
    "        return -1;\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7828c088",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "272c3087",
   "metadata": {},
   "source": [
    "## .txt ve build iÅŸlemleri diÄŸer projelerde olduÄŸunu gibi devam edecektir...\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beaf6c4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
