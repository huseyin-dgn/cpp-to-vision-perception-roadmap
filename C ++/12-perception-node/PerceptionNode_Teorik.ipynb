{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b7c96808",
   "metadata": {},
   "source": [
    "# Perception Node Tasarımı (LibTorch + OpenCV) – Teorik İskelet\n",
    "\n",
    "Bu not defteri, **LibTorch + OpenCV** tabanlı tüm algılama (perception) kodunu\n",
    "*fonksiyon yığını* olmaktan çıkarıp **gerçek bir modüle (Perception Node)** dönüştürmek için teorik iskeleti anlatır.\n",
    "\n",
    "Odak noktamız:\n",
    "\n",
    "- `ImageFrame` veri tipi\n",
    "- `DetectedObject` veri tipi\n",
    "- `PerceptionNode` sınıfı\n",
    "- `constructor`, `preprocess()`, `inference()`, `postprocess()`, `process()` akışı\n",
    "- CNN / YOLO gibi modellerin bu iskelete nasıl oturduğu\n",
    "- Gerçek zamanlı sistemlerde neden bu yapının tercih edildiği\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4160a9dd",
   "metadata": {},
   "source": [
    "## 1. Perception Node Nedir? Sistem İçindeki Yeri\n",
    "\n",
    "Otonom sürüş / robotik mimaride tipik akış:\n",
    "\n",
    "1. **Sensor** (kamera, LiDAR, radar…)\n",
    "2. **Perception** (algılama)\n",
    "3. **Prediction / Planning** (tahmin & planlama)\n",
    "4. **Control** (direksiyon, fren, gaz)\n",
    "\n",
    "Bizim modülümüz: **Perception Node**.\n",
    "\n",
    "- **Girdi (input):** Kamera görüntüsü (ve ilgili metadata)\n",
    "- **Çıktı (output):** Tespit edilen nesneler (sınıf + konum + skor)\n",
    "- **İdeal API:**\n",
    "\n",
    "  ```cpp\n",
    "  auto detections = perception.process(frame);\n",
    "  ```\n",
    "\n",
    "Dışarıdan bakan için önemli olan tek şey:\n",
    "\n",
    "- Bir `ImageFrame` veriyorum.\n",
    "- Bana bir `DetectedObject` listesi dönüyor.\n",
    "\n",
    "İçeride hangi modelin kullanıldığı, kaç adım preprocess olduğu, NMS nasıl yapıldığı dışarıdan **görünmez**.\n",
    "Bu soyutlama, büyük sistemlerde tasarımın temiz kalmasını sağlar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c06bbd",
   "metadata": {},
   "source": [
    "## 2. Neden Sınıf / Modül? Neden Fonksiyon Yığını Değil?\n",
    "\n",
    "Klasik kötü senaryo:\n",
    "\n",
    "- `main.cpp` içinde onlarca fonksiyon:\n",
    "  - `load_model(...)`\n",
    "  - `preprocess(...)`\n",
    "  - `run_inference(...)`\n",
    "  - `postprocess(...)`\n",
    "  - `draw_boxes(...)`\n",
    "  - büyük bir `while (true)` döngüsü\n",
    "\n",
    "Bu yaklaşım şu problemleri doğurur:\n",
    "\n",
    "1. **Bakım zorluğu**\n",
    "   - Tüm mantık tek dosyada toplanır.\n",
    "   - Kod büyüdükçe okunabilirlik düşer.\n",
    "\n",
    "2. **Tekrar kullanım yok**\n",
    "   - Aynı pipeline’ı başka projede kullanmak istersen,\n",
    "     `main.cpp` kopyala–yapıştır yapman gerekir.\n",
    "\n",
    "3. **Gerçek zamanlı mimarilere taşımak zor**\n",
    "   - Multi-thread, ROS2 node, pipeline yapıları kurarken,\n",
    "     dağınık fonksiyonlarla uğraşmak zorlaşır.\n",
    "   - Örneğin ROS2 callback içinde sadece `perception.process(frame)` demek istersin.\n",
    "\n",
    "4. **Kaynak yönetimi dağınık**\n",
    "   - Model açıkça nereye ait belli değildir.\n",
    "   - `torch::jit::script::Module` yükleme, device seçimi, buffer yönetimi gibi işler,\n",
    "     kodun her yerine dağılır.\n",
    "\n",
    "Bu nedenle algılama mantığını tek bir sınıfta toplarız:\n",
    "\n",
    "- Model yükleme → **constructor**\n",
    "- Girdi–çıktı akışı → `process()`\n",
    "- İç detaylar → private fonksiyonlar (`preprocess`, `inference`, `postprocess`)\n",
    "\n",
    "Böylece:\n",
    "\n",
    "- Dışarıdan basit bir arayüz görürüz.\n",
    "- İçerisi modüler ve test edilebilir kalır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5fa46a9",
   "metadata": {},
   "source": [
    "## 3. ImageFrame Veri Tipi\n",
    "\n",
    "Gerçek bir sistemde tek bilgi sadece görüntü değildir.\n",
    "Her frame ile birlikte şu bilgiler de önemli olur:\n",
    "\n",
    "- `image`: `cv::Mat` ham görüntü\n",
    "- `timestamp`: bu frame ne zaman çekildi?\n",
    "- `frame_id`: frame numarası veya benzersiz kimlik\n",
    "- `camera_id` / `camera_name`: hangi kameradan geldi?\n",
    "- Gerekirse kamera parametreleri (kalibrasyon bilgileri vb.)\n",
    "\n",
    "**Neden sadece `cv::Mat` kullanmıyoruz?**\n",
    "\n",
    "- **Senkronizasyon:** Birden fazla sensör olduğunda zaman bilgisi önemlidir.\n",
    "- **Loglama ve debugging:** Hangi frame’de hangi hatalar oldu kolayca takip edilir.\n",
    "- **Latency ölçümleri:** `now - frame.timestamp` ile algılama gecikmesi hesaplanabilir.\n",
    "- **ROS2 / mesajlaşma sistemlerinde header ihtiyacı:** timestamp + frame id bilgisi gerekir.\n",
    "\n",
    "Özet:\n",
    "\n",
    "> **ImageFrame = Görüntü + bağlam (context).**\n",
    "\n",
    "Bu yapı sayesinde tek bir parametre ile hem resmi hem de ilgili tüm metadata’yı taşıyabiliriz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9867f2",
   "metadata": {},
   "source": [
    "## 4. DetectedObject Veri Tipi\n",
    "\n",
    "Bir nesne tespit edildiğinde tipik olarak şu bilgiler tutulur:\n",
    "\n",
    "- `class_id` → modelin sayısal sınıf kimliği\n",
    "- `class_name` → insan okunabilir sınıf ismi (person, car, truck…)\n",
    "- `score` → güven skoru (0.0–1.0 arası)\n",
    "- `bbox` → sınır kutusu (x, y, width, height) piksel cinsinden\n",
    "\n",
    "Opsiyonel alanlar:\n",
    "\n",
    "- `track_id` → zaman içinde aynı nesneyi takip etmek için ID\n",
    "- `distance` / 3D konum bilgisi\n",
    "- `source_frame_id` → hangi frame’den geldiği\n",
    "\n",
    "**Neden ayrı bir tip olarak tanımlıyoruz?**\n",
    "\n",
    "- Diğer modüller (planning, UI, logging) tensor ile değil,\n",
    "  **algılanmış nesne** kavramı ile çalışmak ister.\n",
    "- Model değişse bile (CNN, YOLO, transformer), dışarıya\n",
    "  aynı `DetectedObject` tipini döndürebilmek, kodun geri kalanını\n",
    "  modelden bağımsız hale getirir.\n",
    "\n",
    "Özet:\n",
    "\n",
    "> **DetectedObject = Model çıktısının anlamlı, yüksek seviyeli temsili.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b18241",
   "metadata": {},
   "source": [
    "## 5. PerceptionNode Sınıfı – Genel Sorumluluk\n",
    "\n",
    "`PerceptionNode`, tüm algılama pipeline’ını tek bir modülde toplar.\n",
    "\n",
    "Ana görevleri:\n",
    "\n",
    "- TorchScript modeli yüklemek ve yaşam döngüsünü yönetmek.\n",
    "- Girdi olarak `ImageFrame` alıp, çıktıda `DetectedObject` listesi döndürmek.\n",
    "- Preprocess, inference, postprocess adımlarını **içeride** organize etmek.\n",
    "- Dışarıya sadece **tek bir fonksiyon** sunmak:\n",
    "\n",
    "  ```cpp\n",
    "  std::vector<DetectedObject> process(const ImageFrame& frame);\n",
    "  ```\n",
    "\n",
    "Bu sayede:\n",
    "\n",
    "- Konfigürasyon, model yükleme, cihaz seçimi gibi detaylar gizlenir.\n",
    "- Gerçek zamanlı döngü, ROS2 node veya başka bir pipeline,\n",
    "  sadece bu fonksiyona odaklanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a670eed",
   "metadata": {},
   "source": [
    "### 5.1. PerceptionNode İçinde Tutulacak Üyeler\n",
    "\n",
    "Tipik olarak `PerceptionNode` içinde şu üyeler bulunur:\n",
    "\n",
    "- `torch::jit::script::Module model`\n",
    "  - TorchScript modelin kendisi.\n",
    "  - Constructor’da yüklenir, program süresince hayatta kalır.\n",
    "\n",
    "- `torch::Device device`\n",
    "  - CPU veya CUDA seçimi.\n",
    "  - Tüm tensor oluşturma ve `to()` çağrıları bu cihaza göre yapılır.\n",
    "\n",
    "- Model ile ilgili parametreler:\n",
    "  - Giriş görüntü boyutu (örn. 640x640)\n",
    "  - Normalize için mean / std değerleri\n",
    "  - YOLO ise IoU threshold, skor threshold\n",
    "  - Sınıf isim listesi (`std::vector<std::string> class_names`)\n",
    "\n",
    "- Performans için yardımcı yapılar (opsiyonel):\n",
    "  - Önceden allocate edilmiş input tensor\n",
    "  - Geçici `std::vector<DetectedObject>` buffer’ı\n",
    "\n",
    "Amaç:\n",
    "\n",
    "- Model sadece **bir kez** yüklenir.\n",
    "- Her `process()` çağrısında minimum ek yük (allocation) yaratılır.\n",
    "- Gerçek zamanlı sistemlerde daha stabil ve öngörülebilir süreler elde edilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e2b89b",
   "metadata": {},
   "source": [
    "### 5.2. Constructor – Model Yükleme ve Başlangıç\n",
    "\n",
    "Constructor tipik olarak şu işleri yapar:\n",
    "\n",
    "- TorchScript model dosyasının path’ini alır.\n",
    "- `torch::jit::load(...)` ile modeli yükler.\n",
    "- `device` seçer (CPU / CUDA).\n",
    "- `model.to(device)` ile modeli doğru cihaza taşır.\n",
    "- `model.eval()` ile modeli inference moduna alır.\n",
    "- İsteğe bağlı olarak 1–2 kez dummy input ile **warm-up** yapar.\n",
    "\n",
    "Neden önemlidir?\n",
    "\n",
    "- Model yükleme pahalı bir işlemdir, sadece başlangıçta yapılmalıdır.\n",
    "- Warm-up sayesinde ilk gerçek inference çağrısında gecikme azalır.\n",
    "- Gerçek zamanlı döngü, sürekli model yükleme maliyetine maruz kalmaz.\n",
    "\n",
    "Özet:\n",
    "\n",
    "> Constructor, `PerceptionNode` kurulduğunda modülü\n",
    "> **hazır ve sıcak** hale getirir. `process()` buna dayanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f3fe24a",
   "metadata": {},
   "source": [
    "### 5.3. preprocess() – cv::Mat → torch::Tensor\n",
    "\n",
    "Görev:\n",
    "\n",
    "- `ImageFrame` içindeki `cv::Mat` görüntüyü alır.\n",
    "- Modelin beklediği formata dönüştürür:\n",
    "\n",
    "Tipik adımlar:\n",
    "\n",
    "- Boyutlandırma (resize veya letterbox – YOLO için 640x640 gibi)\n",
    "- Renk uzayı dönüşümü (BGR → RGB)\n",
    "- Tip dönüşümü (`uint8` → `float32`)\n",
    "- Normalizasyon ([0,255] → [0,1], ardından mean/std)\n",
    "- Veri düzeni (H x W x C → C x H x W)\n",
    "- Batch dimension ekleme (1 x C x H x W)\n",
    "\n",
    "Neden ayrı bir fonksiyon?\n",
    "\n",
    "- Preprocess mantığı görüntüye özeldir ve modelden büyük ölçüde bağımsızdır.\n",
    "- Test etmek, profil çıkarmak, ileride GPU hızlandırma eklemek kolaylaşır.\n",
    "- CNN, YOLO, transformer gibi farklı modellere geçerken çoğu zaman\n",
    "  preprocess yapısı benzerdir, küçük farklılıklar izole edilebilir.\n",
    "\n",
    "Özet:\n",
    "\n",
    "> **preprocess():** OpenCV dünyasından **PyTorch tensor** dünyasına geçiş kapısı.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e90bd03",
   "metadata": {},
   "source": [
    "### 5.4. inference() – Girdi Tensor → Ham Model Çıktısı\n",
    "\n",
    "Görev:\n",
    "\n",
    "- Preprocess çıktısı olan input tensor’ü alır.\n",
    "- `model.forward()` ile inference yapar.\n",
    "- Modelin ham çıktısını tensor veya tensor listesi olarak döndürür.\n",
    "\n",
    "Önemli noktalar:\n",
    "\n",
    "- `torch::NoGradGuard` kullanarak gradient hesaplamalarını kapatmak\n",
    "  (inference performansı için).\n",
    "- Model türüne göre çıktı formatını bilmek gerekir:\n",
    "  - CNN classifier: `output.shape = [batch, num_classes]`\n",
    "  - YOLO benzeri detector: `output.shape = [N, 85]` gibi (bbox + skorlar)\n",
    "\n",
    "Neden ayrı bir fonksiyon?\n",
    "\n",
    "- Bu katman en ağır hesap yükünün olduğu yerdir.\n",
    "- Profiling, latency ölçümleri, device geçişleri bu bölümde izlenir.\n",
    "- Alt tarafta CNN → YOLO değişse bile inference çağrı yapısı benzer kalır,\n",
    "  asıl format farkları `postprocess()` içinde çözülür.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1a9e53",
   "metadata": {},
   "source": [
    "### 5.5. postprocess() – Ham Çıkış → DetectedObject Listesi\n",
    "\n",
    "Görev:\n",
    "\n",
    "- Modelden gelen ham tensorleri, `std::vector<DetectedObject>` içine\n",
    "  dönüştürmek.\n",
    "\n",
    "İki örnek üzerinden düşünebiliriz:\n",
    "\n",
    "#### CNN Classifier\n",
    "\n",
    "- Çıktı: `[1, num_classes]` şeklinde bir vektör.\n",
    "- İşlem:\n",
    "  - `argmax` ile en yüksek skorlu sınıfı bul.\n",
    "  - Skoru ve sınıf id’sini al.\n",
    "  - Tüm resmi kapsayan veya mantıklı bir bbox ile tek bir `DetectedObject` oluştur.\n",
    "\n",
    "#### YOLO / Nesne Tespit Modeli\n",
    "\n",
    "- Çıktı: `[N, 85]` gibi (x, y, w, h, obj_score, class_scores...)\n",
    "- Tipik adımlar:\n",
    "  - Bbox koordinatlarını çöz (merkez + genişlik/yükseklik → köşe koordinatları).\n",
    "  - Skor eşiği uygula (score threshold).\n",
    "  - Non-Maximum Suppression (NMS) uygula.\n",
    "  - Kalan kutular için `DetectedObject` oluştur:\n",
    "    - `bbox`\n",
    "    - `class_id`\n",
    "    - `class_name`\n",
    "    - `score`\n",
    "\n",
    "Neden ayrı bir fonksiyon?\n",
    "\n",
    "- Postprocess tamamen **modelin çıktı formatına** bağlıdır.\n",
    "- Aynı `preprocess + inference` iskeletiyle, farklı modeller için\n",
    "  farklı `postprocess()` implementasyonları yazılabilir.\n",
    "- CPU yoğunluğu yüksek olan NMS, filtreleme gibi işlemlerin kontrolü\n",
    "  bu katmanda toplanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71aab99",
   "metadata": {},
   "source": [
    "### 5.6. process() – Dışarı Açılan Tek Kapı\n",
    "\n",
    "`process()` fonksiyonu, dış dünyadan görünen ana API’dir.\n",
    "\n",
    "İç akış:\n",
    "\n",
    "1. `preprocess(frame.image)` → input tensor\n",
    "2. `inference(input_tensor)` → ham model çıktısı\n",
    "3. `postprocess(raw_output)` → `std::vector<DetectedObject>`\n",
    "\n",
    "Dışarıdan kullanım örneği kafada şöyle canlanmalıdır:\n",
    "\n",
    "```cpp\n",
    "PerceptionNode perception(\"model.pt\", config);\n",
    "\n",
    "while (true) {\n",
    "    ImageFrame frame = grab_frame_from_camera();\n",
    "    auto detections = perception.process(frame);\n",
    "    // detections → logla, çiz, publish et, vs.\n",
    "}\n",
    "```\n",
    "\n",
    "Bu tasarımın avantajları:\n",
    "\n",
    "- Algılama mantığı tek bir sınıf içinde toplanır.\n",
    "- Aynı `PerceptionNode` hem:\n",
    "  - Komut satırı programında,\n",
    "  - ROS2 node içinde,\n",
    "  - Multi-thread pipeline’da,\n",
    "  - Unit test senaryolarında\n",
    "  kullanılabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ff873d",
   "metadata": {},
   "source": [
    "## 6. CNN ve YOLO Bu İskelete Nasıl Oturuyor?\n",
    "\n",
    "### 6.1. CNN Classifier Senaryosu\n",
    "\n",
    "- Girdi: Tek nesne içeren crop veya tüm resim.\n",
    "- Çıktı: Sınıf olasılıkları.\n",
    "\n",
    "Pipeline akışı değişmez:\n",
    "\n",
    "1. `preprocess()` → 224x224 resize, normalize, vs.\n",
    "2. `inference()` → `[1, num_classes]` tensor.\n",
    "3. `postprocess()` → tek bir `DetectedObject` (veya hiç).\n",
    "\n",
    "Burada `DetectedObject` sayısı genelde 1’dir.\n",
    "`bbox` isteğe bağlı olarak tüm resmi kapsayacak şekilde kullanılabilir.\n",
    "\n",
    "### 6.2. YOLO / Nesne Tespit Senaryosu\n",
    "\n",
    "- Girdi: Kamera görüntüsü.\n",
    "- Çıktı: Birden fazla nesne için bbox + sınıf + skor.\n",
    "\n",
    "Yine akış aynı:\n",
    "\n",
    "1. `preprocess()` → 640x640 letterbox, normalize.\n",
    "2. `inference()` → ham YOLO çıktısı.\n",
    "3. `postprocess()` → threshold + NMS + `DetectedObject` listesi.\n",
    "\n",
    "Burada her frame için `DetectedObject` sayısı değişebilir (0, 5, 20, ...).\n",
    "\n",
    "Önemli nokta:\n",
    "\n",
    "> **İskelet (constructor, preprocess, inference, postprocess, process) aynı kalır.**\n",
    ">\n",
    "> Sadece `postprocess()` içeriği, modelin çıktı formatına göre uyarlanır.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8de0b5",
   "metadata": {},
   "source": [
    "## 7. Gerçek Zamanlı Sistemler Açısından Neden Doğru Tasarım?\n",
    "\n",
    "Bu modüler yapı, gerçek zamanlı sistemlerde şu avantajları sağlar:\n",
    "\n",
    "### 7.1. Sorumluluk Ayrımı (Separation of Concerns)\n",
    "\n",
    "- Kamera okuma / IO → ayrı modül veya thread\n",
    "- Algılama (`PerceptionNode`) → ayrı modül\n",
    "- Çizim, UI, loglama → ayrı modül\n",
    "\n",
    "Bu sayede kod:\n",
    "\n",
    "- Daha okunabilir,\n",
    "- Daha kolay test edilebilir,\n",
    "- Hata ayıklaması daha rahat yapılabilir hale gelir.\n",
    "\n",
    "### 7.2. Modülerlik ve Değişim Kolaylığı\n",
    "\n",
    "- Aynı API korunarak:\n",
    "  - CPU’dan CUDA’ya geçilebilir.\n",
    "  - CNN’den YOLO’ya geçilebilir.\n",
    "  - Model path’i, input boyutu, threshold’lar değiştirilebilir.\n",
    "\n",
    "Tüm bu değişiklikler sadece `PerceptionNode` içinde yapılır.\n",
    "Dışarıdaki `perception.process(frame)` çağrılarını değiştirmek gerekmez.\n",
    "\n",
    "### 7.3. Multi-thread ve ROS2 Uygunluğu\n",
    "\n",
    "- Bir thread sadece kamera frame’lerini toplar, kuyruğa koyar.\n",
    "- Bir thread bu kuyruktan `ImageFrame` alır ve `process()` çağırır.\n",
    "- ROS2 subscriber callback’i içinde yine sadece `process()` çağrılır,\n",
    "  sonra sonuçlar başka bir topic’e publish edilir.\n",
    "\n",
    "Burada `PerceptionNode`, başlı başına **bağımsız, yeniden kullanılabilir** bir bileşendir.\n",
    "\n",
    "### 7.4. Performans ve Deterministik Davranış\n",
    "\n",
    "- Model sadece bir kere yüklenir, tekrar tekrar kullanılabilir.\n",
    "- `process()` içinde her seferinde aynı adımlar çalışır,\n",
    "  bu da latency ölçümü ve optimizasyonu kolaylaştırır.\n",
    "- Heap allocation’lar azaltılarak daha kararlı FPS elde edilebilir.\n",
    "\n",
    "### 7.5. Test Edilebilirlik\n",
    "\n",
    "- Unit test: Belirli bir `ImageFrame` için beklenen `DetectedObject` sayısı ve tipini kontrol etmek.\n",
    "- Offline test: Video veya kayıtlı frame dizileri üzerinde `PerceptionNode`’u çalıştırıp logları incelemek.\n",
    "\n",
    "Bu sayede hem araştırma/deneme aşamasında hem de üretim ortamında aynı iskelet kullanılabilir.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4f7e1c",
   "metadata": {},
   "source": [
    "## 8. Özet ve Sonraki Aşama\n",
    "\n",
    "Bu teorik iskelet ile şunları netleştirdik:\n",
    "\n",
    "- **ImageFrame** → Görüntü + zaman bilgisi + kamera bağlamı.\n",
    "- **DetectedObject** → Model çıktısının anlamlı temsili (sınıf, bbox, skor).\n",
    "- **PerceptionNode** →\n",
    "  - Modeli yükleyen ve yöneten sınıf,\n",
    "  - `preprocess`, `inference`, `postprocess` adımlarını içinde barındıran modül,\n",
    "  - Dışarıya **sadece** `process(frame)` fonksiyonunu açan temiz bir arayüz.\n",
    "\n",
    "Aynı yapıyı:\n",
    "\n",
    "- CNN classifier,\n",
    "- YOLO tabanlı nesne tespiti,\n",
    "- İleride farklı ağ tipleri\n",
    "\n",
    "için kullanmak mümkündür.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb82828a",
   "metadata": {},
   "source": [
    "# 1) Perception Node Mimarisi (Blok Diagram – Görsel Tasarım)\n",
    "\n",
    "Aşağıdaki tasarım, gerçek bir otonom sistemin perception pipeline’ını temsil ediyor:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0231b3a",
   "metadata": {},
   "source": [
    "```bash\n",
    "┌─────────────────────────┐\n",
    "│       Camera Sensor      │\n",
    "│   (cv::Mat + metadata)   │\n",
    "└──────────────┬───────────┘\n",
    "               │  ImageFrame\n",
    "               ▼\n",
    "       ┌───────────────────┐\n",
    "       │   PerceptionNode  │\n",
    "       │  (LibTorch + CV)  │\n",
    "       └───────┬───────────┘\n",
    "               │\n",
    "               ▼\n",
    "   ┌─────────────────────────────┐\n",
    "   │     preprocess(frame)       │\n",
    "   │  cv::Mat → torch::Tensor    │\n",
    "   └───────────────┬─────────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "   ┌─────────────────────────────┐\n",
    "   │       inference(tensor)     │\n",
    "   │     model.forward()         │\n",
    "   │   TorchScript computation   │\n",
    "   └───────────────┬─────────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "   ┌─────────────────────────────┐\n",
    "   │     postprocess(output)     │\n",
    "   │  bbox + class + score       │\n",
    "   │  NMS / filtering            │\n",
    "   └───────────────┬─────────────┘\n",
    "                   │\n",
    "                   ▼\n",
    "     ┌─────────────────────────┐\n",
    "     │  DetectedObject List    │\n",
    "     │  (class, bbox, score)   │\n",
    "     └───────────────┬─────────┘\n",
    "                     │\n",
    "                     ▼\n",
    "      ┌────────────────────────────┐\n",
    "      │   Downstream Modules       │\n",
    "      │  (Tracking, Planning, UI)  │\n",
    "      └────────────────────────────┘\n",
    "```\n",
    "\n",
    "- Bu diyagram, perception node’un gerçek zamanlı bir sistemde nerede durduğunu, nasıl veri aldığını ve nasıl veri ürettiğini açık biçimde gösterir. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a004b78",
   "metadata": {},
   "source": [
    "----\n",
    "# 2) PerceptionNode.process() Akış Şeması\n",
    "\n",
    "Bu akış şeması direkt olarak process(ImageFrame) fonksiyonunun içsel işleyişini gösterir:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ecaf76",
   "metadata": {},
   "source": [
    "```cpp\n",
    "                   ┌───────────────────────┐\n",
    "                   │  Start process(frame) │\n",
    "                   └───────────────┬───────┘\n",
    "                                   │\n",
    "                                   ▼\n",
    "                     ┌──────────────────────┐\n",
    "                     │  Preprocess Stage    │\n",
    "                     │  - resize            │\n",
    "                     │  - normalize         │\n",
    "                     │  - NHWC → NCHW       │\n",
    "                     └──────────────┬───────┘\n",
    "                                    │  tensor\n",
    "                                    ▼\n",
    "                     ┌──────────────────────┐\n",
    "                     │   Inference Stage    │\n",
    "                     │  model.forward()     │\n",
    "                     ○  NoGradGuard         │\n",
    "                     └──────────────┬───────┘\n",
    "                                    │ raw output\n",
    "                                    ▼\n",
    "                     ┌────────────────────────┐\n",
    "                     │    Postprocess Stage    │\n",
    "                     │  - decode bbox          │\n",
    "                     │  - score threshold      │\n",
    "                     │  - NMS                  │\n",
    "                     │  - DetectedObject list  │\n",
    "                     └───────────────┬────────┘\n",
    "                                     │\n",
    "                                     ▼\n",
    "                          ┌────────────────────┐\n",
    "                          │ return detections  │\n",
    "                          └────────────────────┘\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c3822ef",
   "metadata": {},
   "source": [
    "* Bu akış sayesinde tek bir process() çağrısının içindeki tüm alt aşamaları görsel olarak anlayabilirsin.\n",
    "\n",
    "---\n",
    "\n",
    "# 3) Sistem Seviyesinde Akış (Kamera → Algılama → Uygulama)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da74cc74",
   "metadata": {},
   "source": [
    "* Bunu özellikle ROS2, multi-thread veya otomotiv algılama pipeline’ları için kullanırsın.\n",
    "\n",
    "```bash\n",
    "Camera Thread                  Perception Thread               Application Thread\n",
    "───────────────               ────────────────────             ────────────────────\n",
    "Grab frame                     perception.process(frame)        Track / Plan / UI\n",
    "       │                                  │                         │\n",
    "       ▼                                  ▼                         ▼\n",
    "┌────────────┐                   ┌─────────────────┐         ┌───────────────────┐\n",
    "│ ImageFrame │─────────────────▶ │ DetectedObjects │ ───────▶│ Downstream logic │\n",
    "└────────────┘                   └─────────────────┘         └───────────────────┘\n",
    "```\n",
    "* Bu diyagram gerçek zamanlı sistemlerde thread separation mantığını da doğrudan gösterir."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989ef18e",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f298ffe",
   "metadata": {},
   "source": [
    "---\n",
    "## Proje Yapısı \n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e47d290",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Bu Perception projesinin yapısını böyle kuruyorum\n",
    "### 1. Önce hedefimi net koyuyorum\n",
    "\n",
    "* “Benim amacım, LibTorch + OpenCV kullanan algılama kodumu temiz bir modüle dönüştürmek.\n",
    "* Projede, algılama tarafını PerceptionNode diye ayrı bir sınıfın içine alacağım.\n",
    "* Dışarıdan sadece perception.process(frame) diye çağırmak isteyeceğim.”\n",
    "\n",
    "Bu hedefe göre proje yapısını sade tutuyorum.İlerleyen projelerde daha karmaşık yapılara geçebiliriz.\n",
    "\n",
    "### 2. Klasör ve dosya yapısını oluşturuyorum\n",
    "\n",
    "Projenin ana klasörünü şöyle düşünüyorum:\n",
    "```bash\n",
    "PerceptionProject/\n",
    "  CMakeLists.txt\n",
    "  src/\n",
    "    main.cpp\n",
    "    perception_types.hpp\n",
    "    perception_node.hpp\n",
    "    perception_node.cpp\n",
    "```\n",
    "\n",
    "\n",
    "* CMakeLists.txt → Projenin derleme ayarlarını burada yapıyorum (LibTorch + OpenCV linkleri).\n",
    "\n",
    "* src/main.cpp → Sadece “uygulama” tarafı; kamera açma, frame alma, PerceptionNode kullanımı burada.\n",
    "\n",
    "src/perception_types.hpp → Veri tiplerimi burada tanımlıyorum:\n",
    "\n",
    "* ImageFrame\n",
    "\n",
    "* DetectedObject\n",
    "\n",
    "* PerceptionConfig\n",
    "\n",
    "**src/perception_node.hpp / .cpp → Asıl algılama modülüm:**\n",
    "\n",
    "* Constructor → modeli yüklüyor.\n",
    "\n",
    "* process() → tüm pipeline’ı (preprocess, inference, postprocess) çalıştırıyor.\n",
    "\n",
    "Bunun mantığı:\n",
    "* Algılama mantığı tek bir sınıfta, veri tipleri ayrı bir header’da, uygulama ise main.cpp’de duruyor.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec619eb6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2029ee41",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
